= ÖREB-Kataster richtig gemacht (und einfacher) #3 - ÖREB-Gretljobs
Stefan Ziegler
2022-04-19
:jbake-type: post
:jbake-status: draft
:jbake-tags: ÖREB,ÖREB-Kataster,PostgreSQL,PostGIS,INTERLIS,Gretl,Gradle,ili2pg,ili2db,ilivalidator
:idprefix:

Im dritten Teil schlägt die Stunde der ÖREB-Gretljobs. Gretljobs? Gretl?

Als wir uns vor Jahren daran machten unser Cronjob- und Datenintegrationschaos (oder allgemeiner ETL-Prozess) zu beseitigen, kamen wir auf die Idee ein Build-Tool zu verwenden. Der Grund für diese Entscheidung war, dass ein solcher Prozess (= Job) immer in Teilschritte (= Tasks) runtergebrochen werden kann. Beispiel: Daten werden heruntergeladen (Task 1), Daten werden entzippt (Task 2), Daten werden geprüft (Task 3), Daten werden importiert (Task 4) und Daten werden in eine andere Datenbankstruktur umgebaut (Task 5). Als Build-Tool verwenden wir https://gradle.org[_Gradle_]. Einerseits gibt es out-of-the-box bereits viele Funktionen und Plugins und andererseits ist es relativ einfach erweiterbar. Erweiterbar muss es sein, weil wir ein paar &laquo;Geo-Tasks&raquo; benötigen (z.B. INTERLIS-Import etc.) oder Funktionen, die es weder im Core noch in einem Plugin gibt. Unsere Erweiterungen packten wir ebenfalls in ein https://plugins.gradle.org/plugin/ch.so.agi.gretl[Plugin] und somit war https://github.com/sogis/gretl[Gretl (Gradle ETL)] geboren.

Ein minimales Beipiel, das eine INTERLIS-Datei prüft, sieht wie folgt aus (der Code muss in einer `build.gradle`-Datei erstellt werden): 

[source,groovy,linenums]
----
import ch.so.agi.gretl.tasks.*
import ch.so.agi.gretl.api.*

apply plugin: 'ch.so.agi.gretl'

buildscript {
    repositories {
        maven { url "http://jars.interlis.ch" }
        maven { url "http://jars.umleditor.org" }
        maven { url "https://repo.osgeo.org/repository/release/" }
        maven { url "https://plugins.gradle.org/m2/" }
        mavenCentral()
    }
    dependencies {
        classpath group: 'ch.so.agi', name: 'gretl',  version: '2.1.+'
    }
}

defaultTasks 'validate'


task validate(type: IliValidator){
    dataFiles = ["fubar.xtf"]
}
----

Im Verzeichnis, wo die `build.gradle`-Datei liegt, kann man den Job mit `gradle` aufgerufen werden. Die zu prüfende Datei `fubar.xtf` muss natürlich auf vorhanden sein und _gradle_ installiert sein. Das interessante sind die sogenannten Tasks. Von diesen Tasks kann es beliebig viele geben und sie können auch voneinander abhängig (`dependsOn`) sein. Einen Überblick über alle unsere Jobs (und Inspiration) erlangt man in unserem https://github.com/sogis/gretljobs/[gretljobs-Repo]. Eine möglichst vollständige Dokumentation unserer selbst programmierten Task findet man ebenfalls im https://github.com/sogis/gretl/blob/master/docs/user/index.md[Repo] oder man kann sich die https://pretalx.com/fossgis2019/talk/ESDMQB/[Präsentation von Gretl] an einer Fossgis zu Gemüte führen. Die ganze Sache läuft nun seit circa fünf Jahren und wir könnten zufriedener nicht sein. Zur Orchestrierung sämtliche Jobs verwenden wir übrigens Jenkins, was sich ebenfalls sehr bewährt hat: Perfekte Übersicht über sämtliche Jobs und Logfiles immer am gleichen Ort. Viel mehr braucht es nicht:

image::../../../../../images/oerebk_richtig_gemacht_p03/jenkins.png[alt="gretl jenkins", align="center"]

Jenkins soll hier beim Datenimport in die ÖREB-Datenbank keine Rolle spielen, da ein Gretl-Job eben auch ganz ohne Schnick-Schnack in der Konsole ausgeführt werden kann. Wir haben das Gretl-Plugin mit sämtlichen Abhängigkeiten in ein https://hub.docker.com/repository/docker/sogis/gretl[Docker-Image] gepackt. So sind wir sicher, dass wir immer die gleichen Versionen der Abhängigkeiten verwenden und sind zugleich unabhängig von einer Java-Installation. Das Image ist seit kurzem auch auf einem Apple Silicon Rechner lauffähig. Man sieht: eine gewisse Leidensfähigkeit und Durchhaltewillen als Macbook-Anwender der neueren Generation muss man mitbringen.

Zurück zum eigentlichen Ziel: Dem Import aller benötigten Daten in die ÖREB-Datenbank (aus http://blog.sogeo.services/blog/2022/04/18/oereb-kataster-richtig-gemacht-2.html[Teil 2]) für den Betrieb des ÖREB-Katasters. Und mit allen Daten sind eben nicht nur Geodaten gemeint, sondern auch Konfiguration im weiteren Sinne, d.h. Gesetzliche Grundlagen, Themen, Logos, Texte. Falls nötig sowohl für Bund und Kanton (Gemeinden). Ein wichtige Konfiguration im engeren Sinne sind die freigeschalteten Gemeinden (wo ist der ÖREB-Kataster verfügbar?). Dafür gibt es im Modell `OeREBKRMkvs_V2_0` die Klasse `GemeindeMitOeREBK`. In dieser Klasse kann man feingranular verwalten welche Themen in welcher Gemeinde vorhanden sind. Alle diese Daten(sätze) sind bei uns in einer INTERLIS-Transferdatei vorhanden resp. für die Bundesthemen stellt sie bereits Swisstopo https://models.geo.admin.ch/V_D/OeREB/[zur Verfügung]. Es gibt absolut keine Notwendigkeit diese Konfigurationen mit etwas selber Definiertem zu verwalten.

Stehen die Datensätze online zur Verfügung, müssen die Gretl-Jobs diese nur noch herunterladen, validieren und importieren (siehe http://blog.sogeo.services/blog/2022/04/17/oereb-kataster-richtig-gemacht-1.html[Teil 1] &laquo;sauberer Schnitt&raquo; und &laquo;Zuständigkeiten&raquo;). Matchentscheidend ist die Reihenfolge wie die Gretl-Jobs ausgeführt werden: Die Daten werden in eine Datenbank importiert. Die Beziehungen zwischen Klassen werden mittels Fremdschlüsseln abgebildet. D.h. man kann keine Daten importieren, wenn die Daten auf ein Objekt zeigen, dass noch nicht in der Datenbank vorhanden ist. In unserem Fall müssen zwingend die zuständigen Stellen vorhanden sein, falls diese nicht mit den Geobasisdaten mitgeliefert werden. Man kann (mit einer ili2pg-Option) das Erstellen der Fremdschlüsseln ausschalten, was aber meines Erachtens nicht sinnvoll ist. Diese gibt es ja aus guten Gründen und wenn man immer und immer wieder Daten in den DB-Tabellen austauscht, passiert garantiert irgendwann mal ein Fehler und die Daten passen nicht mehr zusammen. Herausfordernd wird es wenn - bleiben wir beim Beispiel der zuständigen Stellen - der Name oder die Adresse der zuständigen Stelle ändert. Dieser Record kann ich der Datenbank nicht ausgetauscht werden, weil ein anderer Record einen Fremdschlüssel auf diesen Record hat. Die meisten Fälle können mit ili2db-Magie gelöst werden indem man die `--update`-Option verwendet. Dann wird das Objekt in der Datenbank nicht gelöscht, sondern - nomen est omen - upgedatet. Das funktioniert natürlich nicht, wenn das Amt gelöscht werden soll und es immer noch Objekte gibt, die auf diese Amt verweisen. Dann bleibt einem nichts anderes übrig, als zuerst diese Objekte zu löschen und anschliessend auch das Amt (Stichwort Transaktion).

Gradle (das Build-Tool, die Basis von Gretl) bietet verschiedene Hilfsmittel wie die Reihenfolge von einzelnen Tasks garantieren kann (`dependsOn`, `mustRunAfter`, `finalizedBy`). Bei der Organisation der Gretl-Jobs sind der Fantasie keine Grenzen gesetzt. Es gibt viele richtige Varianten. Im vorliegenden Fall habe ich mich technisch für einen Haupt-Gretl-Job entschieden, der aus verschiedenen Sub-Jobs besteht. So kann man mit einem Befehl alles Notwendige importieren aber trotzdem noch einzelne Schritte selbständig ausführen, z.B. das Ersetzen sämtlicher Bundesgeobasisdaten. Ein Blick hinter die Kulissen erlaubt das https://github.com/oereb/oereb-gretljobs[Gretljobs-Repo]. Die Mutter aller Jobs ist XXXXXXXXXX mit dem Task....

Klickt man sich ein wenig zur die einzelnen `build.gradle`-Dateien an, sehen alle sehr ähnlich aus. Ich denke, man sieht sehr gut, dass sie die Arbeit (also der Sub-Job) in einzelne kleine Schritte (= Tasks) aufgesplittet wurde, was der Transparenz sehr zuträglich ist (Fehlersuche etc.). Die vorliegende Aufteilung ist vielleicht nicht ultra-konsistent was darauf zurück zu führen ist, dass ich vieles von unseren Gretl-Jobs für den ÖREB-Kataster übernommen habe und für Demo-Zwecke nicht zwingend sinnvoll gruppiert ist.




```

```
network...

Import nur in `live`-Schema....

referenzielle integrität... update  / fk problematik / Bemerkung
Reihenfolge

nicht ultra-stringent bezüglich namensgebung und packetierung. Aber man sieht, dass wir für alle Konfig eine entsprechend INTERLIS-Transferdatei (im Rahmenmodell) haben. 

Reihenfolge ist für gewissen Daten(sätze) entscheidend. Ansonsten kann man sich das zusammenstöpseln wie man will und wie es für die eigene Organisation am besten ist.

Unser ÖREB-Webservcie (Teil 5) benötigt eine Verfügbar-Dataset (-> Klasse?). Sonst weiss er nicht, welche Gemeinde freigeschaltet sind.

Daten aus unserer Test-Umgebung.

WMS-updates nicht vergessen.