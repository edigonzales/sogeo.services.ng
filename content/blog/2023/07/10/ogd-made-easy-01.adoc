= OGD made easy #1 - csv2parquet
Stefan Ziegler
2023-07-10
:jbake-type: post
:jbake-status: published
:jbake-tags: OGD,INTERLIS,Java,CSV,Parquet
:idprefix:

Ob https://so.ch[wir] überhaupt mal OGD machen werden, steht noch in den Sternen. Es schadet aber wohl nichts, sich ein paar Gedanken zu den Abläufen und dem Einsatz und Zusammenspiel einzelner Komponenten zu machen. Synergien zu den Prozessen und den Werkzeugen in unserer https://geo.so.ch/[GDI] gibt es mit genügend grosser Wahrscheinlichkeit.

CSV-Dateien spielen anscheinend eine https://www.stadt-zuerich.ch/portal/de/index/ogd/werkstatt/csv.html[grosse] https://www.zh.ch/de/politik-staat/opendata/leitlinien.html#-932898780[Rolle]. Gehen wir also davon aus, dass Fachstellen ihre offenen Daten im CSV-Format anliefern. Ein paar Fragen, die sich stellen:

- Wie beschreibt man CSV-Daten? (z.B. Was bedeutet das Attribut <xxx> genau?)
- Wie kontrolliert man CSV-Daten?
- Soll man neben CSV (und dem Klassiker XLSX) noch weitere, &laquo;bessere&raquo; Formate bereitstellen?

Die ersten beiden Fragestellungen lassen sich mit INTERLIS erledigen. Eine Antwort auf die letzte Fragen könnte https://en.wikipedia.org/wiki/Apache_Parquet[Parquet] sein. Parquet ist ein spaltenorientiertes Dateiformat. Die Spezifikation ist quelloffen. Es eignet sich gut für die Abfrage und Verarbeitung von Daten. Oder vielleicht am Profansten: Es gibt Datentypen, Rätselraten war gestern.

Was nun CSV mit INTERLIS zu tun hat und wie man eine CSV-Datei in eine Parquet-Datei umwandeln kann, zeige ich anhand meines kleinen Prototypes https://github.com/edigonzales/csv2parquet[_csv2parquet_]. Es handelt sich dabei um eine Java-Kommandozeilenanwendung und dient momentan vor allem Anschauungs- und Testzwecken. Früher oder später würde die Umwandlung bei uns wohl in unserer ETL-Werkzeug https://github.com/sogis/gretl[GRETL] integriert werden. Heruntergeladen werden kann die aktuellste Version https://github.com/edigonzales/csv2parquet/releases/[hier]. Die Zip-Datei entpacken und das Shell-Skript resp. die Batch-Datei auführen:

```
./bin/csv2parquet --help
```

In der Konsole sollte der Hilfetext erscheinen. Die Anforderungen an die Anwendung sind moderat (Java 8 reicht). Leider muss man gefühlt das halbe Internet herunterladen. Die Zip-Datei ist 70MB gross. Der Grund dafür sind die - für mich und viele anderen - unnötigen Hadoop-Abhängigkeiten der https://github.com/apache/parquet-mr[Parquet-Bibliothek]. Es gibt einen https://issues.apache.org/jira/browse/PARQUET-1822?page=com.atlassian.jira.plugin.system.issuetabpanels%3Aall-tabpanel[Issue] dazu. Vergessen wir das wieder und konzentrieren uns auf die Funktionen und erstellen die erste Parquet-Datei aus einer CSV-Datei. Ausgewählt habe ich die https://raw.githubusercontent.com/edigonzales/csv2parquet/b9172dd298f7b55a45eb89e4deb0b5009de58300/src/test/data/bewilligte_erdwaermeanlagen/bewilligte_erdwaermeanlagen.csv[bewilligten Erdwärmeanlagen]. Das https://afu.so.ch[Amt für Umwelt] stellt viele Daten bereits heute freundlicherweise https://so.ch/verwaltung/bau-und-justizdepartement/amt-fuer-umwelt/umweltdaten/[online]. Der einfachst mögliche Aufruf ist:


```
./bin/csv2parquet -i bewilligte_erdwaermeanlagen.csv
```

Damit das einfach so funktioniert, werden Annahmen bezüglich des Trennzeichens (Separator) und des Feldtrenners (Delimiter) getroffen. Standardwert für das Trennzeichen ist ein Semikolon und für den Feldtrenner ein leeres Zeichen (also kein Feldtrenner). Das entspricht dem Output von Excel:

[source,xml,linenums]
----
jahr;anfragen;bewilligte_anlagen;durchschnittlicher_oelpreis_pro_1000_liter;bewilligte_erdsonden;bewilligte_erdkollektoren;sondenlaenge_km;heizleistung_kw;internet_clicks_durchschnitt_pro_monat
1991;28;28;;26;2;;;
1992;67;33;;26;7;;;
1993;99;26;;24;2;;;
----

Wenn kein Zielverzeichnis (`--output`) angegeben wird, wird versucht die Parquet-Datei in das Quellverzeichnis zu schreiben. Jetzt haben wir zwar eine Paquet-Datei aber kann man sie anschauen? 



https://duckdb.org/docs/guides/sql_editors/dbeaver.html



iox-reader... / writer.





attribute immer gleich 





bug fix / local timestamp... nicht ganz deckungsglelich avro und parrquet (m.E.) PITA!!! 

https://www.stadt-zuerich.ch/portal/de/index/ogd/werkstatt/csv.html

Ob cli überhaupt im Einsatz bleibt/kommt, keine Ahnung. Es muss als GRETL-Task implementiert werden und vielleicht als Webservice.


http://blog.sogeo.services/blog/2022/11/01/interlis-leicht-gemacht-number-31.html[Letzten Herbst] habe ich https://github.com/edigonzales/ili2c-native/releases[_ili2c_], https://github.com/edigonzales/ili2pg-native/releases[_ilivalidator_] und https://github.com/edigonzales/ilivalidator-native/releases[_ili2pg_] mit https://www.graalvm.org/[_GraalVM_] zu einem https://www.graalvm.org/latest/reference-manual/native-image/[Native Image] kompiliert. Daraus resultiert - im Gegensatz zu den https://downloads.interlis.ch[offiziell publizierten] Versionen - eine betriebssystemabhängige Variante, die jedoch keine Java-Installation benötigt. Das Kompilieren übernimmt eine Github Action und somit können mindestens drei Betriebssysteme (Windows, Ubuntu-Linux, macOS) problemlos angeboten werden.

Einen Haken hat die ganze Sache aber: Die Performance ist https://github.com/claeis/ilivalidator/issues/364[massiv schlechter] als bei den Java-Varianten. Dies wird vor allem bei der Prüfung mit ilivalidator zum Problem. Es gab bereits relativ lange eine Enterprise-Version von GraalVM, die sich diesem Problem annahm. Die Java-Variante kann in unserem Fall anscheinend massiv vom JIT-Compiler profitieren und während der Laufzeit immer mehr den Code optimieren. Das ist mit einem Native Image nicht mehr möglich. Das muss alles vorher passieren. Dies ist bei der Enterprise-Variante mit https://www.graalvm.org/22.0/reference-manual/native-image/PGO/[&laquo;Profile-Guided Optimizations&raquo;] möglich. Die Anwendung wird zuerst geprofiled und dabei Informationen gesammelt. Mit diesen Informationen wird  anschliessend der Native Image Builder gefüttert und daraus sollte eine bessere Performance resultieren. Eine zweite Baustelle ist der Garbager Collector. Die Community-Variante verfügt nur über den Serial GC, die Enterprise-Variante zusätzlich über den Garbage First Garbage Collector (G1GC), jedoch nur unter Linux. Nun hat aber auch die Enterprise-Variante einen Haken und man vermutet wohl richtig: Enterprise == $. 

Mit dem neusten GraalVM-Release (Version 23) gibt es keine Enterprise-Variante mehr. Der Nachfolger heisst &laquo;Oracle GraalVM&raquo; und ist https://medium.com/graalvm/a-new-graalvm-release-and-new-free-license-4aab483692f5[frei]. Man sollte sich sicherheitshalber wohl die https://www.oracle.com/downloads/licenses/graal-free-license.html[&laquo;GraalVM Free Terms and Conditions (GFTC) license&raquo;] und die https://www.oracle.com/java/technologies/javase/jdk-faqs.html#GraalVM-licensing[FAQ] gut durchlesen.

Mit all den Enterprise-Feature, die nun frei verfügbar sind, steht einem Performance-Vergleich nichts mehr im Wege. Geprüft wird ilivalidator 1.13.3 mit unserem https://data.geo.so.ch/proxy?file=https://files.geo.so.ch/ch.so.alw.fruchtfolgeflaechen/aktuell/ch.so.alw.fruchtfolgeflaechen.xtf.zip[Fruchtfolgeflächen-Datensatz]. Zuerst habe ich nur die einzelnen Objekte geprüft (`--singlePass`). Das hat zur Folge, dass die AREA-Prüfung nicht ausgeführt wird. Als Testrechner habe einen Hetzner-Cloud-Server verwendet.

[cols="1,1"]
|===
|Variante |Dauer (mins:secs)

|Standard 
|1:33
|PGO
|1:00
|PGO und G1GC
|1:04
|JVM
|0:33
|===

Eine spürbare Verbesserung vor allem dank PGO ist sichtbar. Gegen die JVM-Variante haben die Native Images aber immer noch keine Chance. Wie sieht es aus, wenn ich das XTF komplett prüfe (also v.a. inklusive der AREA-Prüfung):

[cols="1,1"]
|===
|Variante |Dauer (mins:secs)

|Standard 
|13:32
|PGO
|10:13
|PGO und G1GC
|8:19
|JVM
|6:08
|===

Die Unterschiede werden grösser. Die PGO+G1GC-Variante ist fünf Minuten schneller als die Standardvariante. Es gibt zwar immer noch eine Lücke zur reinen Java-Variante zu schliessen, aber absolut faszinierend was sich rausholen lässt mit einem anderen Garbage Collector und den PGO.

Wie sieht es bei _ili2pg_ aus? Die Datenbank läuft in einem Docker-Container. Die Prüfung des Datensatzes wurde ausgeschaltet (`--disableValidation`):

[cols="1,1"]
|===
|Variante |Dauer (mins:secs)

|Standard 
|0:40
|PGO
|0:35
|PGO und G1GC
|0:19
|JVM
|0:20
|===

Es bräuchte wohl grössere Datensätze, um hier grössere Abstände zu sehen. Jedenfalls scheint PGO+G1GC auch hier gut mithalten zu können. Der Einfluss der Anwendung dürfte auf die reine Ausführungszeit geringer sein, da die Datenbank natürlich viel abarbeiten muss.

Die _ilitools_ als Native Image werden immer interessanter und dank der frei verfügbaren Oracle GraalVM Distribution ist die Herstellung auch kein Problem mehr.
